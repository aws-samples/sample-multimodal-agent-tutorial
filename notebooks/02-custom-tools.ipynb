{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Custom Tools for Multi-Modal Processing\n",
    "\n",
    "Extend agents with custom tools using the `@tool` decorator. This notebook demonstrates how to process multi-modal content including images, videos, and documents with custom tool implementations.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Create custom tools with the `@tool` decorator\n",
    "- Process images, videos, and documents\n",
    "- Handle multi-modal content in agent workflows\n",
    "- Implement error handling and validation in tools\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed [Notebook 01: Hello World](01-hello-world-strands-agents.ipynb)\n",
    "- Understanding of Python functions and decorators\n",
    "- Sample media files (provided in `data-sample/` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.tools import tool\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-tool",
   "metadata": {},
   "source": [
    "## Creating a Simple Tool\n",
    "\n",
    "Let's create a simple calculator tool (using @tool decorator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculator-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"Performs basic mathematical operations.\n",
    "    \n",
    "    Args:\n",
    "        operation: The operation to perform (add, subtract, multiply, divide)\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \n",
    "    Returns:\n",
    "        The result of the operation\n",
    "    \"\"\"\n",
    "    operations = {\n",
    "        \"add\": a + b,\n",
    "        \"subtract\": a - b,\n",
    "        \"multiply\": a * b,\n",
    "        \"divide\": a / b if b != 0 else \"Error: Division by zero\"\n",
    "    }\n",
    "    return operations.get(operation, \"Invalid operation\")\n",
    "\n",
    "print(\"âœ… Calculator tool created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "use-tool",
   "metadata": {},
   "source": [
    "## Using Tools with Agents\n",
    "\n",
    "Let's first create the model instance to be used by the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Bedrock model\n",
    "session = boto3.Session(region_name='us-east-1')\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    boto_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665875cc",
   "metadata": {},
   "source": [
    "Now let's create an agent that can use our calculator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent-with-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with calculator tool\n",
    "math_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[calculator],\n",
    "    system_prompt=\"You are a helpful math assistant. Use the calculator tool to perform calculations.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Math agent created with calculator tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the calculator tool\n",
    "response = math_agent(\"What is 156 multiplied by 23?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eeab64",
   "metadata": {},
   "source": [
    "Now let's inspect the type AgentResult in Strands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the AgentResult object\n",
    "print(f\"Message: {response.message}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"Metrics: {response.metrics}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"State: {response.state}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"Stop Reason: {response.stop_reason}\")\n",
    "print(\"-\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-tool",
   "metadata": {},
   "source": [
    "## Creating More Complex Tools\n",
    "\n",
    "Let's create a tool that gets current time information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "time-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time(timezone: str = \"UTC\") -> str:\n",
    "    \"\"\"Gets the current date and time.\n",
    "    \n",
    "    Args:\n",
    "        timezone: The timezone (currently only UTC supported)\n",
    "    \n",
    "    Returns:\n",
    "        Current date and time as a string\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current time ({timezone}): {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "print(\"âœ… Time tool created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-time-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with multiple tools\n",
    "assistant = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[calculator, get_current_time],\n",
    "    system_prompt=\"You are a helpful assistant with access to calculator and time tools.\"\n",
    ")\n",
    "\n",
    "response = assistant(\"What time is it? Also, what's 50 plus 75?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "builtin-tools",
   "metadata": {},
   "source": [
    "## Using Built-in Tools\n",
    "\n",
    "Strands Agents includes pre-built tools for common tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "builtin-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands_tools import image_reader, file_read \n",
    "# Example of video_reader tool structure\n",
    "# (This is already implemented in video_reader.py)\n",
    "\n",
    "from video_reader_local import video_reader_local\n",
    "\n",
    "# Create agent with built-in tools\n",
    "multimodal_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[image_reader, file_read,video_reader_local],\n",
    "    system_prompt=\"\"\"You are a multi-modal assistant that can:\n",
    "    - Read and analyze images\n",
    "    - Process documents (PDF, CSV, DOCX, etc.)\n",
    "    - Use advanced reasoning for complex tasks.\n",
    "    - Analyze videos and provide detailed insights.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-modal agent created with built-in tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c145eeb",
   "metadata": {},
   "source": [
    "We can see which tools are loaded in our agent in `agent.tool_name`, along with a JSON representation of the tools in `agent.tool_config` that also includes the tool descriptions and input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multimodal_agent.tool_names)\n",
    "\n",
    "print(multimodal_agent.tool_registry.get_all_tools_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63053aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Image analysis\n",
    "print(\"=== ðŸ“¸ IMAGE ANALYSIS ===\")\n",
    "image_result = multimodal_agent(\"Analyze the image data-sample/diagram.jpg in detail and describe everything you observe\")\n",
    "# print(image_result)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Document analysis (if you have a PDF document)\n",
    "print(\"=== ðŸ“„ DOCUMENT ANALYSIS ===\")\n",
    "doc_result = multimodal_agent(\"Summarize as json the content of the document data-sample/Welcome-Strands-Agents-SDK.pdf\")\n",
    "# print(doc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Video analysis\n",
    "print(\"=== ðŸŽ¬ VIDEO ANALYSIS ===\")\n",
    "video_result = multimodal_agent(\"Analyze the video data-sample/climbing-video.mp4 and describe in detail the actions and scenes you observe\")\n",
    "print(video_result)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the AgentResult object\n",
    "print(f\"Message: {video_result.message}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"Metrics: {video_result.metrics}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"State: {video_result.state}\")\n",
    "print(\"-\" * 100 + \"\\n\")\n",
    "\n",
    "print(f\"Stop Reason: {video_result.stop_reason}\")\n",
    "print(\"-\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-tool-use",
   "metadata": {},
   "source": [
    "## Direct Tool Usage\n",
    "\n",
    "You can also call tools directly from the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multimodal_agent.tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-call",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4. Direct use of tools\n",
    "video_analysis = multimodal_agent.tool.video_reader_local(\n",
    "     video_path=\"data-sample/climbing-video.mp4\", \n",
    "     text_prompt=\"What are the main elements in this video?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ca7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b7cbd",
   "metadata": {},
   "source": [
    "### Additional Samples\n",
    "An agent that uses the video reader using a AWS S3 bucket for larger videos. \n",
    "\n",
    "For that you need to add the bucket environment variable\n",
    "\n",
    "```bash\n",
    "export VIDEO_READER_S3_BUCKET = \"YOU-BUCKET-NAME\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands_tools import image_reader, file_read \n",
    "# Example of video_reader tool structure\n",
    "# (This is already implemented in video_reader.py)\n",
    "\n",
    "from video_reader import video_reader\n",
    "\n",
    "\n",
    "# Create agent with built-in tools\n",
    "multimodal_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    tools=[image_reader, file_read,video_reader],\n",
    "    system_prompt=\"\"\"You are a multi-modal assistant that can:\n",
    "    - Read and analyze images\n",
    "    - Process documents (PDF, CSV, DOCX, etc.)\n",
    "    - Use advanced reasoning for complex tasks.\n",
    "    - Analyze videos and provide detailed insights.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Multi-modal agent created with built-in tools!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa311e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4. Direct use of tools\n",
    "video_analysis = multimodal_agent.tool.video_reader_local(\n",
    "     video_path=\"data-sample/moderation-video.mp4\", \n",
    "     text_prompt=\"What are the main elements in this video?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59c9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "âœ… How to create custom tools with the `@tool` decorator\n",
    "\n",
    "âœ… How to add tools to agents\n",
    "\n",
    "âœ… How to use built-in tools from strands_tools\n",
    "\n",
    "âœ… How to create agents with multiple tools\n",
    "\n",
    "âœ… How to call tools directly\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to the next notebook to learn about Model Context Protocol (MCP) integration!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db262c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
